import os, sys, ctypes

for p in (
    r'./build/faiss/python',
    r'C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin',
    r'C:\Program Files (x86)\Intel\oneAPI\compiler\2025.2\bin',
    r'C:\Program Files (x86)\Intel\oneAPI\mkl\2025.2\bin'
):
    p = os.path.abspath(p)
    os.add_dll_directory(p)
    sys.path.append(p)

try:
    from swigfaiss import *
    # from swigfaiss_avx2 import *
except ImportError:
    raise RuntimeError("Can't import swigfaiss pyd")


# %%
import numpy as np, faiss, time

# %%

# The below code is generated by LLM:
# GPU self-check
ngpu = faiss.get_num_gpus()
print(f"[INFO] Num GPUs detected by FAISS: {ngpu}")
if ngpu == 0:
    raise RuntimeError("Can't find GPU")

# %%

# Parameters (adjust as needed; Flat complexity ~ nb*nq*d)
d   = 64
nb  = 200_000
nq  = 40_000           # Increase batch size to avoid launch/scheduling overhead dominating
k   = 10
seed = 123

rs = np.random.RandomState(seed)
xb = rs.randn(nb, d).astype('float32')
xq = rs.randn(nq, d).astype('float32')

xb = rs.randn(nb, d).astype('float32')
# Make the vectors have a "small structure" for sanity check
xb[:100, :] += 3
xq = (rs.randn(nq, d)).astype('float32')
xq[:5, :] += 3

# ---- CPU baseline ----
cpu = faiss.IndexFlatL2(d)
t0 = time.perf_counter()
cpu.add(xb)
t1 = time.perf_counter()
Dcpu, Icpu = cpu.search(xq, k)
t2 = time.perf_counter()
print(f"[CPU] add {1e3*(t1-t0):.1f} ms  search {1e3*(t2-t1):.1f} ms")

# ---- GPU: Explicit configuration + warmup + large temporary memory + FP16 + transposed storage ----
res = faiss.StandardGpuResources()
try:
    # Increase temporary memory (default ~256 MiB, too small will fragment/block a lot)
    res.setTempMemory(512 * 1024 * 1024)  # 512 MiB; If there is enough memory, it can be 1~2 GiB
except Exception:
    pass

cfg = faiss.GpuIndexFlatConfig()
cfg.device = 0
cfg.useFloat16 = True          # Use FP16 GEMM, L2 distance accuracy is enough, and the speed is significantly improved
cfg.storeTransposed = True     # 对 xb 做转置，加速 GEMM 访存
cfg.indicesOptions = faiss.INDICES_32_BIT

gpu = faiss.GpuIndexFlatL2(res, d, cfg)

# Add directly on the GPU index (avoid the implicit overhead of each clone/move)
t0 = time.perf_counter()
gpu.add(xb)
t1 = time.perf_counter()

# Warmup (CUDA/LT engine, first JIT/TF32 enabled)
_ = gpu.search(xq[:min(1024, nq)], k)

# Large batch/chunk search (avoid too large or too small)
def search_in_chunks(index, q, k, bs=8192):
    Ds, Is = [], []
    for i in range(0, len(q), bs):
        D, I = index.search(q[i:i+bs], k)
        Ds.append(D); Is.append(I)
    return np.vstack(Ds), np.vstack(Is)

t2 = time.perf_counter()
Dgpu, Igpu = search_in_chunks(gpu, xq, k, bs=8192)
t3 = time.perf_counter()

print(f"[GPU] add {1e3*(t1-t0):.1f} ms  search {1e3*(t3-t2):.1f} ms   (FP16, transposed, temp=512MiB)")

# ---- Consistency (usually completely consistent or only a few in the same order)----
top1 = (Icpu[:,0] == Igpu[:,0]).mean()
inter = [len(set(Icpu[i]).intersection(Igpu[i]))/k for i in range(len(xq))]
print(f"[CHK] top1={100*top1:.2f}%  mean recall@{k}={100*np.mean(inter):.2f}%")

# %%
dlls = [
    "libiomp5md.dll",
    "mkl_intel_thread.2.dll",
    "cublas64_12.dll",
    "python312.dll",
    "MSVCP140.dll",
    "VCRUNTIME140.dll",
    "VCRUNTIME140_1.dll",
]

for d in dlls:
    try:
        ctypes.CDLL(d)
        print(f"[OK] {d}")
    except OSError as e:
        print(f"[MISSING] {d} → {e}")
